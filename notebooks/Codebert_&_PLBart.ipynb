{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Create dataset"
      ],
      "metadata": {
        "id": "tHqBgUUyaLq-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uScOxMVS0vAf",
        "outputId": "a3cf63f1-c0b0-4682-86fa-5ee1e273e179"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1rks7UbT8Bbl7TdQvfqoXx6fXhaPM8xOv\n",
            "To: /content/augmented_kernel_quality.csv\n",
            "100% 75.8M/75.8M [00:00<00:00, 135MB/s]\n"
          ]
        }
      ],
      "source": [
        "!gdown 1rks7UbT8Bbl7TdQvfqoXx6fXhaPM8xOv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "ZISeOWKJSMdE"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "api_token = {\"username\":\"_\",\"key\":\"_\"}\n",
        "\n",
        "import json\n",
        "\n",
        "with open('kaggle.json', 'w') as file:\n",
        "  json.dump(api_token, file)\n",
        "\n",
        "!chmod 600 kaggle.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "BMwzJevJyChR"
      },
      "outputs": [],
      "source": [
        "os.environ[\"KAGGLE_CONFIG_DIR\"] = \"/content\""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Get code+markdown for 1050 new ground truth"
      ],
      "metadata": {
        "id": "QGwZu8eQLBOc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "df_test = pd.read_csv('experts.csv')\n",
        "df_test['expert_score'] = df_test['expert_score'].astype(int)\n"
      ],
      "metadata": {
        "id": "P02U71ZGta8R"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "from kaggle import api\n",
        "import time\n",
        "\n",
        "codes = []\n",
        "markdowns = []\n",
        "errors = []\n",
        "\n",
        "for i, row in df_test.iterrows():\n",
        "  try:\n",
        "    out = api.kernel_pull(row['UserName'], row['CurrentUrlSlug'])\n",
        "    src = out['blob']['source']\n",
        "    code = ' \\n '.join([x['source'] for x in json.loads(src)['cells'] if x['cell_type'] == 'code'])\n",
        "    markdown = ' \\n '.join([x['source'] for x in json.loads(src)['cells'] if x['cell_type'] == 'markdown'])\n",
        "    codes.append(code)\n",
        "    markdowns.append(markdown)\n",
        "    time.sleep(2)\n",
        "  except:\n",
        "    errors.append(i)"
      ],
      "metadata": {
        "id": "DiQhJ3zYtmNd"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "notebooks = df_test.copy()\n",
        "notebooks.index = range(len(df_test))\n",
        "notebooks = notebooks.drop(errors)\n",
        "notebooks['code'] = codes\n",
        "notebooks['markdown'] = markdowns"
      ],
      "metadata": {
        "id": "qtpC21P33oIC"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "notebooks[['KernelId', 'code', 'markdown', 'label']].to_csv('1050_train_codebert.csv', index=False)"
      ],
      "metadata": {
        "id": "9_fSYh_R37EN"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp 1050_train_codebert.csv drive/MyDrive/Meta_Kaggle/"
      ],
      "metadata": {
        "id": "xn1vQSVt4QeW"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Get code+markdown for 10k samples"
      ],
      "metadata": {
        "id": "kjftMgjPLJTZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "YYuXbFD8yK1c"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "kernel_quality = pd.read_csv('augmented_kernel_quality.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "plCdYGP51fm0"
      },
      "outputs": [],
      "source": [
        "kernel_quality = kernel_quality[kernel_quality['TotalViews'] >= 500]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "7q-3m0Hi1UOR"
      },
      "outputs": [],
      "source": [
        "kernel_quality['score'] = (kernel_quality['TotalVotes'] + 1) / kernel_quality['TotalViews']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "IiWQaZcd2-Pj"
      },
      "outputs": [],
      "source": [
        "kernel_quality.sort_values(by=['score'], inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "PQjJf62s3QrB"
      },
      "outputs": [],
      "source": [
        "sample_len = 10**4\n",
        "samples = pd.concat([kernel_quality.head(sample_len // 2), kernel_quality.tail(sample_len // 2)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "lvUlN8OPkj3i"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "from kaggle import api\n",
        "import time\n",
        "\n",
        "codes = []\n",
        "markdowns = []\n",
        "errors = []\n",
        "\n",
        "for i, row in samples.iterrows():\n",
        "  try:\n",
        "    out = api.kernel_pull(row['UserName'], row['CurrentUrlSlug'])\n",
        "    src = out['blob']['source']\n",
        "    code = ' \\n '.join([x['source'] for x in json.loads(src)['cells'] if x['cell_type'] == 'code'])\n",
        "    markdown = ' \\n '.join([x['source'] for x in json.loads(src)['cells'] if x['cell_type'] == 'markdown'])\n",
        "    codes.append(code)\n",
        "    markdowns.append(markdown)\n",
        "    time.sleep(2)\n",
        "  except:\n",
        "    errors.append(i)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "notebooks = samples.copy()\n",
        "notebooks.index = range(len(samples))\n",
        "notebooks = notebooks.drop(errors)\n",
        "notebooks['code'] = codes\n",
        "notebooks['markdown'] = markdowns"
      ],
      "metadata": {
        "id": "9nwHCPLRLdBM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "_BuoRoBnyOrt"
      },
      "outputs": [],
      "source": [
        "notebooks[['KernelId', 'code', 'markdown', 'score']].to_csv('10000_train_codebert.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "56Zr0ll1mKWA"
      },
      "outputs": [],
      "source": [
        "!cp 10000_train_codebert.csv drive/MyDrive/Meta_Kaggle/"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup training data"
      ],
      "metadata": {
        "id": "vUIuU9p2WuID"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown 15jJ04nVQb3wIGih696kWaizugiyxNKj5"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RR0EDzUaWw2x",
        "outputId": "bef194db-70e5-4abe-c737-b7375311f923"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=15jJ04nVQb3wIGih696kWaizugiyxNKj5\n",
            "To: /content/5000_train_codebert.csv\n",
            "100% 77.1M/77.1M [00:00<00:00, 123MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown 1uR9olJJXEpTBEVodeuM-SEgtiMRS9czA"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3H3HSafiXQsH",
        "outputId": "ee0819c7-d12b-4a99-8b93-94d3072e57e2"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1uR9olJJXEpTBEVodeuM-SEgtiMRS9czA\n",
            "To: /content/10000_train_codebert.csv\n",
            "100% 49.3M/49.3M [00:02<00:00, 21.6MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "zeros = pd.read_csv('./10000_train_codebert.csv')\n",
        "ones = pd.read_csv('./5000_train_codebert.csv')"
      ],
      "metadata": {
        "id": "v7QIuIb0XThW"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ones = ones.head(len(zeros))"
      ],
      "metadata": {
        "id": "4L1cVMR7XmN2"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "zeros['label'] = 0\n",
        "ones['label'] = 1"
      ],
      "metadata": {
        "id": "pFxNVrP7XoXt"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.concat([zeros, ones])"
      ],
      "metadata": {
        "id": "bl9JmT_HX1yx"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.dropna(subset=['code'], inplace=True)"
      ],
      "metadata": {
        "id": "9cdMEUK_X-JU"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.fillna('', inplace=True)"
      ],
      "metadata": {
        "id": "6zSh7xTMYYgP"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train Codebert"
      ],
      "metadata": {
        "id": "RbYypMWOsgjD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## functions and imports"
      ],
      "metadata": {
        "id": "BZZXoAP9RF9M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q transformers accelerate\n",
        "!pip install datasets -q\n",
        "!pip install evaluate -q"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AEAZlOK1aAJf",
        "outputId": "09751894-11e4-4669-fcda-376531989afc"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m297.6/297.6 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m542.0/542.0 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m388.9/388.9 kB\u001b[0m \u001b[31m25.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import json\n",
        "import evaluate\n",
        "from datasets import Dataset, DatasetDict\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "import torch\n",
        "from transformers import AutoModelForSequenceClassification\n",
        "from transformers import TrainingArguments, Trainer"
      ],
      "metadata": {
        "id": "jIaCblzBZ9yt"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_dataset(data):\n",
        "  X_train, X_eval, y_train, y_eval = train_test_split(data[['code', 'markdown']], data['label'], test_size=0.10, random_state=1)\n",
        "  X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size=0.25, random_state=1)\n",
        "  df_train = pd.DataFrame({'code': X_train['code'], 'markdown': X_train['markdown'], 'label': y_train})\n",
        "  df_eval = pd.DataFrame({'code': X_eval['code'], 'markdown': X_eval['markdown'], 'label': y_eval})\n",
        "  df_test = pd.DataFrame({'code': X_test['code'], 'markdown': X_test['markdown'], 'label': y_test})\n",
        "  dataset = DatasetDict({\n",
        "      \"train\": Dataset.from_pandas(df_train),\n",
        "      \"eval\": Dataset.from_pandas(df_eval),\n",
        "      \"test\": Dataset.from_pandas(df_test),\n",
        "  })\n",
        "  return dataset\n",
        "\n",
        "def tokenize_function(examples):\n",
        "  markdown_max_len = 300\n",
        "  truncated_markdown = [markdown[:markdown_max_len] for markdown in examples['markdown']]\n",
        "\n",
        "  result = tokenizer(\n",
        "      truncated_markdown,\n",
        "      examples['code'],\n",
        "      truncation=True,\n",
        "      padding='max_length',\n",
        "      return_tensors='pt',\n",
        "  )\n",
        "  return result\n",
        "\n",
        "def tokenize_dataset(dataset, tokenizer):\n",
        "  tokenized_dataset = dataset.map(tokenize_function, batched=True)\n",
        "  return tokenized_dataset\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "  logits, labels = eval_pred\n",
        "  predictions = np.argmax(logits, axis=-1)\n",
        "  metric = evaluate.load(\"accuracy\")\n",
        "  return metric.compute(predictions=predictions, references=labels)\n",
        "\n",
        "def create_trainer(tokenized_dataset, model, num_train_epochs, logging_steps):\n",
        "  device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "  model.to(device)\n",
        "  for param in model.roberta.parameters():\n",
        "      param.requires_grad = False\n",
        "\n",
        "  training_args = TrainingArguments(output_dir=\"test_trainer\", evaluation_strategy=\"epoch\",\n",
        "                                    num_train_epochs=num_train_epochs, log_level='debug', logging_steps=logging_steps,)\n",
        "  training_args.do_predict = True\n",
        "  training_args.do_train = True\n",
        "  training_args.do_eval = True\n",
        "  trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_dataset[\"train\"].shuffle(seed=42),\n",
        "    eval_dataset=tokenized_dataset[\"eval\"].shuffle(seed=42),\n",
        "    compute_metrics=compute_metrics,\n",
        "  )\n",
        "  return trainer"
      ],
      "metadata": {
        "id": "ANAa32sCsU-o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = \"microsoft/codebert-base\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2)"
      ],
      "metadata": {
        "id": "YkiQQHW2sw7U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Chart for accuracy precision recall f1 on test set"
      ],
      "metadata": {
        "id": "0Q6lSmWlQ4L7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "models = ['1K', '2K', '4K', '8K', '10K',]\n",
        "accuracy =  [0.64, 0.68, 0.71, 0.71, 0.71,]\n",
        "precision = [0.62, 0.66, 0.71, 0.72, 0.71,]\n",
        "recall =    [0.64, 0.68, 0.68, 0.71, 0.72,]\n",
        "f1 =        [0.62, 0.67, 0.69, 0.71, 0.71,]\n",
        "\n",
        "data = pd.DataFrame({'Model': models * 4,\n",
        "                     'Metric': ['Accuracy'] * 5 + ['Precision'] * 5 + ['Recall'] * 5 + ['F1'] * 5,\n",
        "                     'Score': accuracy + precision + recall + f1})\n",
        "\n",
        "# Plot using Seaborn\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.barplot(x='Model', y='Score', hue='Metric', data=data, palette='Set2')\n",
        "plt.title('Performance Metrics of Training Baseline Model\\nwith Different Data Sizes Tested on Test Set')\n",
        "plt.xlabel('Models')\n",
        "plt.ylabel('Scores')\n",
        "plt.legend(title='Metrics', bbox_to_anchor=(1, 1.05), loc='upper left')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 607
        },
        "id": "uhTU5rUhTN5p",
        "outputId": "eaf51fbe-3cae-4e45-e55a-c9cd1442c56d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Chart for accuracy precision recall f1 on GT"
      ],
      "metadata": {
        "id": "A9SBRU0kRAE0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "models = ['1K', '2K', '4K', '8K', '10K',]\n",
        "accuracy =  [0.59, 0.60, 0.62, 0.61, 0.62,]\n",
        "precision = [0.57, 0.58, 0.62, 0.62, 0.61,]\n",
        "recall =    [0.58, 0.60, 0.60, 0.61, 0.62,]\n",
        "f1 =        [0.57, 0.59, 0.61, 0.61, 0.61,]\n",
        "\n",
        "data = pd.DataFrame({'Model': models * 4,\n",
        "                     'Metric': ['Accuracy'] * 5 + ['Precision'] * 5 + ['Recall'] * 5 + ['F1'] * 5,\n",
        "                     'Score': accuracy + precision + recall + f1})\n",
        "\n",
        "# Plot using Seaborn\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.barplot(x='Model', y='Score', hue='Metric', data=data, palette='Set2')\n",
        "plt.title('Performance Metrics of Training Baseline Model\\nwith Different Data Sizes Tested on Ground Truth')\n",
        "plt.xlabel('Models')\n",
        "plt.ylabel('Scores')\n",
        "plt.legend(title='Metrics', bbox_to_anchor=(1, 1.05), loc='upper left')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 607
        },
        "id": "ymebwvEKQ_o7",
        "outputId": "7ab4370c-7928-464e-ec2f-6a4324e8e314"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load GT"
      ],
      "metadata": {
        "id": "v1MHd39ZPpxA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown 14tqOq2fmW90LhaCpXhRvQstqW1DI9c2S"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yTHblVXgo7nc",
        "outputId": "985e1030-8013-4eb3-ebf0-f4fa8f8a8007"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=14tqOq2fmW90LhaCpXhRvQstqW1DI9c2S\n",
            "To: /content/1050_train_codebert.csv\n",
            "100% 15.4M/15.4M [00:00<00:00, 72.6MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_test = pd.read_csv('1050_train_codebert.csv')\n",
        "df_test.dropna(subset=['code'], inplace=True)\n",
        "df_test.fillna('', inplace=True)\n",
        "df_test.dropna(inplace=True)"
      ],
      "metadata": {
        "id": "AOaNLtdnMrWF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_test_input = pd.DataFrame({'code': df_test['code'], 'markdown': df_test['markdown'], 'label': df_test['label']})\n",
        "test_dataset = DatasetDict({\n",
        "  \"test\": Dataset.from_pandas(df_test_input),\n",
        "})\n",
        "\n",
        "tokenized_test_dataset = tokenize_dataset(test_dataset, tokenizer)"
      ],
      "metadata": {
        "id": "9Cl59oxSM0iJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train with 1k samples"
      ],
      "metadata": {
        "id": "ZidvgBTxsnwZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = df.sample(1000)\n",
        "dataset = create_dataset(data)\n",
        "tokenized_dataset = tokenize_dataset(dataset, tokenizer)\n",
        "trainer = create_trainer(tokenized_dataset, model, 10, 10)"
      ],
      "metadata": {
        "id": "10ctRETtspyS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_result = trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "1qzvtp9-appb",
        "outputId": "6f425aa9-8cdd-473f-a6aa-9c09defa9e49"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Currently training with a batch size of: 8\n",
            "The following columns in the training set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: code, markdown, __index_level_0__. If code, markdown, __index_level_0__ are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running training *****\n",
            "  Num examples = 675\n",
            "  Num Epochs = 10\n",
            "  Instantaneous batch size per device = 8\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 850\n",
            "  Number of trainable parameters = 592,130\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='850' max='850' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [850/850 04:38, Epoch 10/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.692500</td>\n",
              "      <td>0.676775</td>\n",
              "      <td>0.580000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.690400</td>\n",
              "      <td>0.725250</td>\n",
              "      <td>0.420000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.702100</td>\n",
              "      <td>0.668008</td>\n",
              "      <td>0.600000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.681000</td>\n",
              "      <td>0.679526</td>\n",
              "      <td>0.630000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.664200</td>\n",
              "      <td>0.706550</td>\n",
              "      <td>0.420000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.681600</td>\n",
              "      <td>0.659093</td>\n",
              "      <td>0.630000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.666700</td>\n",
              "      <td>0.673682</td>\n",
              "      <td>0.660000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.655700</td>\n",
              "      <td>0.671386</td>\n",
              "      <td>0.670000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.672200</td>\n",
              "      <td>0.675498</td>\n",
              "      <td>0.600000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.650500</td>\n",
              "      <td>0.674204</td>\n",
              "      <td>0.630000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: code, markdown, __index_level_0__. If code, markdown, __index_level_0__ are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 100\n",
            "  Batch size = 8\n",
            "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: code, markdown, __index_level_0__. If code, markdown, __index_level_0__ are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 100\n",
            "  Batch size = 8\n",
            "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: code, markdown, __index_level_0__. If code, markdown, __index_level_0__ are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 100\n",
            "  Batch size = 8\n",
            "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: code, markdown, __index_level_0__. If code, markdown, __index_level_0__ are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 100\n",
            "  Batch size = 8\n",
            "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: code, markdown, __index_level_0__. If code, markdown, __index_level_0__ are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 100\n",
            "  Batch size = 8\n",
            "Checkpoint destination directory test_trainer/checkpoint-500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
            "Saving model checkpoint to test_trainer/checkpoint-500\n",
            "Configuration saved in test_trainer/checkpoint-500/config.json\n",
            "Model weights saved in test_trainer/checkpoint-500/model.safetensors\n",
            "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: code, markdown, __index_level_0__. If code, markdown, __index_level_0__ are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 100\n",
            "  Batch size = 8\n",
            "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: code, markdown, __index_level_0__. If code, markdown, __index_level_0__ are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 100\n",
            "  Batch size = 8\n",
            "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: code, markdown, __index_level_0__. If code, markdown, __index_level_0__ are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 100\n",
            "  Batch size = 8\n",
            "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: code, markdown, __index_level_0__. If code, markdown, __index_level_0__ are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 100\n",
            "  Batch size = 8\n",
            "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: code, markdown, __index_level_0__. If code, markdown, __index_level_0__ are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 100\n",
            "  Batch size = 8\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "metrics = train_result.metrics\n",
        "trainer.save_model()  # Saves the tokenizer too for easy upload\n",
        "\n",
        "trainer.log_metrics(\"train\", metrics)\n",
        "trainer.save_metrics(\"train\", metrics)\n",
        "trainer.save_state()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z8sgJV87astA",
        "outputId": "b407855b-b658-489d-c02a-4c1294492cfc"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Saving model checkpoint to test_trainer\n",
            "Configuration saved in test_trainer/config.json\n",
            "Model weights saved in test_trainer/model.safetensors\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "***** train metrics *****\n",
            "  epoch                    =       10.0\n",
            "  total_flos               =  1654028GF\n",
            "  train_loss               =     0.6817\n",
            "  train_runtime            = 0:04:38.69\n",
            "  train_samples_per_second =      24.22\n",
            "  train_steps_per_second   =       3.05\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluation\n",
        "\n",
        "metrics = trainer.evaluate(eval_dataset=tokenized_dataset[\"eval\"].shuffle(seed=42))\n",
        "\n",
        "trainer.log_metrics(\"eval\", metrics)\n",
        "trainer.save_metrics(\"eval\", metrics)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 257
        },
        "id": "h2FFgV0las--",
        "outputId": "267b6fa3-67fa-41ef-b504-0e9ff4793afd"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: code, markdown, __index_level_0__. If code, markdown, __index_level_0__ are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 100\n",
            "  Batch size = 8\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='13' max='13' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [13/13 00:03]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "***** eval metrics *****\n",
            "  epoch                   =       10.0\n",
            "  eval_accuracy           =       0.63\n",
            "  eval_loss               =     0.6742\n",
            "  eval_runtime            = 0:00:03.35\n",
            "  eval_samples_per_second =     29.786\n",
            "  eval_steps_per_second   =      3.872\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Prediction\n",
        "\n",
        "predictions, labels, metrics = trainer.predict(tokenized_dataset[\"test\"], metric_key_prefix=\"predict\")\n",
        "\n",
        "trainer.log_metrics(\"predict\", metrics)\n",
        "trainer.save_metrics(\"predict\", metrics)\n",
        "\n",
        "predictions = np.argmax(predictions, axis=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        },
        "id": "6vd64yb9auAW",
        "outputId": "148fbdda-ec77-433c-8471-c6a0ae70adac"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following columns in the test set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: code, markdown, __index_level_0__. If code, markdown, __index_level_0__ are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Prediction *****\n",
            "  Num examples = 225\n",
            "  Batch size = 8\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "***** predict metrics *****\n",
            "  predict_accuracy           =       0.64\n",
            "  predict_loss               =     0.6621\n",
            "  predict_runtime            = 0:00:07.79\n",
            "  predict_samples_per_second =     28.847\n",
            "  predict_steps_per_second   =      3.718\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(predictions, labels, labels=[0, 1]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VYGCRqgvavBQ",
        "outputId": "f12cb916-d3bf-4b71-fc50-4557b0604e8e"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.46      0.64      0.53        72\n",
            "           1       0.79      0.64      0.71       153\n",
            "\n",
            "    accuracy                           0.64       225\n",
            "   macro avg       0.62      0.64      0.62       225\n",
            "weighted avg       0.68      0.64      0.65       225\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train with 2k samples"
      ],
      "metadata": {
        "id": "IJ6KqqfPvILP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = df.sample(2000)\n",
        "dataset = create_dataset(data)\n",
        "tokenized_dataset = tokenize_dataset(dataset, tokenizer)\n",
        "trainer = create_trainer(tokenized_dataset, model, 10, 10)"
      ],
      "metadata": {
        "id": "FIefw5GU8MVs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_result = trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "a8217906742a4a288280654e0d038082",
            "20b8849626d94f709fb9e33c195cc519",
            "22be0b89bf464b3e957a4b6f7929778e",
            "79863b216774407dbd255892723b94b8",
            "d6e6390eea474faa8dfc3610d8f4ce19",
            "a877d22e6cf8408db522fb424c35760a",
            "88fbd91d45304b42b2a1b4d5dff4ad92",
            "d79193961099446b8296f070019e1091",
            "91c3e1de89cc4270beefbf0addb2df1a",
            "37c2b69483d24ac5bd6e454d0d55b53b",
            "0c29de6b5a054459bd756b83c222a997"
          ]
        },
        "id": "xFBrE_k4-rph",
        "outputId": "6b54aecb-6123-4b7f-b9f9-77e9c02d3f2c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Currently training with a batch size of: 8\n",
            "The following columns in the training set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: __index_level_0__, code, markdown. If __index_level_0__, code, markdown are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running training *****\n",
            "  Num examples = 1,350\n",
            "  Num Epochs = 10\n",
            "  Instantaneous batch size per device = 8\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 1,690\n",
            "  Number of trainable parameters = 592,130\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1690' max='1690' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1690/1690 09:19, Epoch 10/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.689400</td>\n",
              "      <td>0.704932</td>\n",
              "      <td>0.445000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.685000</td>\n",
              "      <td>0.675178</td>\n",
              "      <td>0.555000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.680200</td>\n",
              "      <td>0.661891</td>\n",
              "      <td>0.665000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.659300</td>\n",
              "      <td>0.667012</td>\n",
              "      <td>0.640000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.645700</td>\n",
              "      <td>0.647279</td>\n",
              "      <td>0.635000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.676200</td>\n",
              "      <td>0.644324</td>\n",
              "      <td>0.590000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.647600</td>\n",
              "      <td>0.652114</td>\n",
              "      <td>0.655000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.629100</td>\n",
              "      <td>0.642429</td>\n",
              "      <td>0.670000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.645200</td>\n",
              "      <td>0.638015</td>\n",
              "      <td>0.670000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.656600</td>\n",
              "      <td>0.639712</td>\n",
              "      <td>0.675000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: __index_level_0__, code, markdown. If __index_level_0__, code, markdown are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 200\n",
            "  Batch size = 8\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading builder script:   0%|          | 0.00/4.20k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a8217906742a4a288280654e0d038082"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: __index_level_0__, code, markdown. If __index_level_0__, code, markdown are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 200\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to test_trainer/tmp-checkpoint-500\n",
            "Configuration saved in test_trainer/tmp-checkpoint-500/config.json\n",
            "Model weights saved in test_trainer/tmp-checkpoint-500/model.safetensors\n",
            "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: __index_level_0__, code, markdown. If __index_level_0__, code, markdown are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 200\n",
            "  Batch size = 8\n",
            "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: __index_level_0__, code, markdown. If __index_level_0__, code, markdown are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 200\n",
            "  Batch size = 8\n",
            "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: __index_level_0__, code, markdown. If __index_level_0__, code, markdown are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 200\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to test_trainer/tmp-checkpoint-1000\n",
            "Configuration saved in test_trainer/tmp-checkpoint-1000/config.json\n",
            "Model weights saved in test_trainer/tmp-checkpoint-1000/model.safetensors\n",
            "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: __index_level_0__, code, markdown. If __index_level_0__, code, markdown are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 200\n",
            "  Batch size = 8\n",
            "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: __index_level_0__, code, markdown. If __index_level_0__, code, markdown are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 200\n",
            "  Batch size = 8\n",
            "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: __index_level_0__, code, markdown. If __index_level_0__, code, markdown are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 200\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to test_trainer/tmp-checkpoint-1500\n",
            "Configuration saved in test_trainer/tmp-checkpoint-1500/config.json\n",
            "Model weights saved in test_trainer/tmp-checkpoint-1500/model.safetensors\n",
            "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: __index_level_0__, code, markdown. If __index_level_0__, code, markdown are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 200\n",
            "  Batch size = 8\n",
            "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: __index_level_0__, code, markdown. If __index_level_0__, code, markdown are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 200\n",
            "  Batch size = 8\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "metrics = train_result.metrics\n",
        "trainer.save_model()  # Saves the tokenizer too for easy upload\n",
        "\n",
        "trainer.log_metrics(\"train\", metrics)\n",
        "trainer.save_metrics(\"train\", metrics)\n",
        "trainer.save_state()\n",
        "\n",
        "# Evaluation\n",
        "\n",
        "metrics = trainer.evaluate(eval_dataset=tokenized_dataset[\"eval\"].shuffle(seed=42))\n",
        "\n",
        "trainer.log_metrics(\"eval\", metrics)\n",
        "trainer.save_metrics(\"eval\", metrics)\n",
        "\n",
        "# Prediction\n",
        "\n",
        "predictions, labels, metrics = trainer.predict(tokenized_dataset[\"test\"], metric_key_prefix=\"predict\")\n",
        "\n",
        "trainer.log_metrics(\"predict\", metrics)\n",
        "trainer.save_metrics(\"predict\", metrics)\n",
        "\n",
        "predictions = np.argmax(predictions, axis=1)\n",
        "\n",
        "print(classification_report(predictions, labels, labels=[0, 1]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 762
        },
        "id": "fufpOv5m-uT8",
        "outputId": "64b9c732-259d-401e-a76b-75d2cf8d21c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Saving model checkpoint to test_trainer\n",
            "Configuration saved in test_trainer/config.json\n",
            "Model weights saved in test_trainer/model.safetensors\n",
            "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: __index_level_0__, code, markdown. If __index_level_0__, code, markdown are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 200\n",
            "  Batch size = 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "***** train metrics *****\n",
            "  epoch                    =       10.0\n",
            "  total_flos               =  3308057GF\n",
            "  train_loss               =     0.6638\n",
            "  train_runtime            = 0:09:22.65\n",
            "  train_samples_per_second =     23.993\n",
            "  train_steps_per_second   =      3.004\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following columns in the test set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: __index_level_0__, code, markdown. If __index_level_0__, code, markdown are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Prediction *****\n",
            "  Num examples = 450\n",
            "  Batch size = 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "***** eval metrics *****\n",
            "  epoch                   =       10.0\n",
            "  eval_accuracy           =      0.675\n",
            "  eval_loss               =     0.6397\n",
            "  eval_runtime            = 0:00:07.60\n",
            "  eval_samples_per_second =     26.308\n",
            "  eval_steps_per_second   =      3.289\n",
            "***** predict metrics *****\n",
            "  predict_accuracy           =     0.6844\n",
            "  predict_loss               =     0.6351\n",
            "  predict_runtime            = 0:00:16.00\n",
            "  predict_samples_per_second =     28.109\n",
            "  predict_steps_per_second   =       3.56\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.70      0.71      0.71       240\n",
            "           1       0.67      0.65      0.66       210\n",
            "\n",
            "    accuracy                           0.68       450\n",
            "   macro avg       0.68      0.68      0.68       450\n",
            "weighted avg       0.68      0.68      0.68       450\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Test with GT"
      ],
      "metadata": {
        "id": "Xgzf0SGwMqBr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predictions, labels, metrics = trainer.predict(tokenized_test_dataset['test'], metric_key_prefix=\"predict\")\n",
        "\n",
        "trainer.log_metrics(\"predict\", metrics)\n",
        "trainer.save_metrics(\"predict\", metrics)\n",
        "\n",
        "predictions = np.argmax(predictions, axis=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        },
        "id": "l6xSoj0-qHhy",
        "outputId": "ab8a1db1-d383-4e6e-d8a0-b77e8a14f009"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following columns in the test set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: __index_level_0__, code, markdown. If __index_level_0__, code, markdown are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Prediction *****\n",
            "  Num examples = 991\n",
            "  Batch size = 8\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "***** predict metrics *****\n",
            "  predict_accuracy           =     0.5954\n",
            "  predict_loss               =     0.6642\n",
            "  predict_runtime            = 0:00:36.60\n",
            "  predict_samples_per_second =     27.076\n",
            "  predict_steps_per_second   =      3.388\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(predictions, labels, labels=[0, 1]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IZJgt0rUqeFx",
        "outputId": "40cbf3d3-c8e1-4ce4-de54-c9883340ae70"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.56      0.61      0.58       465\n",
            "           1       0.63      0.59      0.61       526\n",
            "\n",
            "    accuracy                           0.60       991\n",
            "   macro avg       0.60      0.60      0.60       991\n",
            "weighted avg       0.60      0.60      0.60       991\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train with 4k samples"
      ],
      "metadata": {
        "id": "Q95XYQfjNLKh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = df.sample(4000)\n",
        "dataset = create_dataset(data)\n",
        "tokenized_dataset = tokenize_dataset(dataset, tokenizer)\n",
        "trainer = create_trainer(tokenized_dataset, model, 10, 10)"
      ],
      "metadata": {
        "id": "kF6t0hJnNOn4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_result = trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "NTQ3u7D0T_yG",
        "outputId": "f015a70d-ae2d-4224-aea4-e57747c7048c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Currently training with a batch size of: 8\n",
            "The following columns in the training set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: __index_level_0__, code, markdown. If __index_level_0__, code, markdown are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running training *****\n",
            "  Num examples = 2,700\n",
            "  Num Epochs = 10\n",
            "  Instantaneous batch size per device = 8\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 3,380\n",
            "  Number of trainable parameters = 592,130\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='3380' max='3380' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [3380/3380 18:50, Epoch 10/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.672800</td>\n",
              "      <td>0.671799</td>\n",
              "      <td>0.522500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.644700</td>\n",
              "      <td>0.647652</td>\n",
              "      <td>0.662500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.688100</td>\n",
              "      <td>0.648802</td>\n",
              "      <td>0.592500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.711300</td>\n",
              "      <td>0.626143</td>\n",
              "      <td>0.655000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.668600</td>\n",
              "      <td>0.613160</td>\n",
              "      <td>0.670000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.623700</td>\n",
              "      <td>0.604414</td>\n",
              "      <td>0.690000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.629300</td>\n",
              "      <td>0.598861</td>\n",
              "      <td>0.695000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.593200</td>\n",
              "      <td>0.618031</td>\n",
              "      <td>0.652500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.600400</td>\n",
              "      <td>0.592445</td>\n",
              "      <td>0.712500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.593000</td>\n",
              "      <td>0.590288</td>\n",
              "      <td>0.722500</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: __index_level_0__, code, markdown. If __index_level_0__, code, markdown are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 400\n",
            "  Batch size = 8\n",
            "Checkpoint destination directory test_trainer/checkpoint-500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
            "Saving model checkpoint to test_trainer/checkpoint-500\n",
            "Configuration saved in test_trainer/checkpoint-500/config.json\n",
            "Model weights saved in test_trainer/checkpoint-500/model.safetensors\n",
            "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: __index_level_0__, code, markdown. If __index_level_0__, code, markdown are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 400\n",
            "  Batch size = 8\n",
            "Checkpoint destination directory test_trainer/checkpoint-1000 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
            "Saving model checkpoint to test_trainer/checkpoint-1000\n",
            "Configuration saved in test_trainer/checkpoint-1000/config.json\n",
            "Model weights saved in test_trainer/checkpoint-1000/model.safetensors\n",
            "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: __index_level_0__, code, markdown. If __index_level_0__, code, markdown are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 400\n",
            "  Batch size = 8\n",
            "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: __index_level_0__, code, markdown. If __index_level_0__, code, markdown are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 400\n",
            "  Batch size = 8\n",
            "Checkpoint destination directory test_trainer/checkpoint-1500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
            "Saving model checkpoint to test_trainer/checkpoint-1500\n",
            "Configuration saved in test_trainer/checkpoint-1500/config.json\n",
            "Model weights saved in test_trainer/checkpoint-1500/model.safetensors\n",
            "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: __index_level_0__, code, markdown. If __index_level_0__, code, markdown are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 400\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to test_trainer/tmp-checkpoint-2000\n",
            "Configuration saved in test_trainer/tmp-checkpoint-2000/config.json\n",
            "Model weights saved in test_trainer/tmp-checkpoint-2000/model.safetensors\n",
            "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: __index_level_0__, code, markdown. If __index_level_0__, code, markdown are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 400\n",
            "  Batch size = 8\n",
            "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: __index_level_0__, code, markdown. If __index_level_0__, code, markdown are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 400\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to test_trainer/tmp-checkpoint-2500\n",
            "Configuration saved in test_trainer/tmp-checkpoint-2500/config.json\n",
            "Model weights saved in test_trainer/tmp-checkpoint-2500/model.safetensors\n",
            "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: __index_level_0__, code, markdown. If __index_level_0__, code, markdown are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 400\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to test_trainer/tmp-checkpoint-3000\n",
            "Configuration saved in test_trainer/tmp-checkpoint-3000/config.json\n",
            "Model weights saved in test_trainer/tmp-checkpoint-3000/model.safetensors\n",
            "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: __index_level_0__, code, markdown. If __index_level_0__, code, markdown are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 400\n",
            "  Batch size = 8\n",
            "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: __index_level_0__, code, markdown. If __index_level_0__, code, markdown are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 400\n",
            "  Batch size = 8\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "metrics = train_result.metrics\n",
        "trainer.save_model()  # Saves the tokenizer too for easy upload\n",
        "\n",
        "trainer.log_metrics(\"train\", metrics)\n",
        "trainer.save_metrics(\"train\", metrics)\n",
        "trainer.save_state()\n",
        "\n",
        "# Evaluation\n",
        "\n",
        "metrics = trainer.evaluate(eval_dataset=tokenized_dataset[\"eval\"].shuffle(seed=42))\n",
        "\n",
        "trainer.log_metrics(\"eval\", metrics)\n",
        "trainer.save_metrics(\"eval\", metrics)\n",
        "\n",
        "# Prediction\n",
        "\n",
        "predictions, labels, metrics = trainer.predict(tokenized_dataset[\"test\"], metric_key_prefix=\"predict\")\n",
        "\n",
        "trainer.log_metrics(\"predict\", metrics)\n",
        "trainer.save_metrics(\"predict\", metrics)\n",
        "\n",
        "predictions = np.argmax(predictions, axis=1)\n",
        "\n",
        "print(classification_report(predictions, labels, labels=[0, 1]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 762
        },
        "id": "iuDrU195UAAx",
        "outputId": "1c9a19cf-58d1-4a0d-d053-1e8e9941ff8e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Saving model checkpoint to test_trainer\n",
            "Configuration saved in test_trainer/config.json\n",
            "Model weights saved in test_trainer/model.safetensors\n",
            "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: code, markdown, __index_level_0__. If code, markdown, __index_level_0__ are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 400\n",
            "  Batch size = 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "***** train metrics *****\n",
            "  epoch                    =       10.0\n",
            "  total_flos               =  6616114GF\n",
            "  train_loss               =     0.6452\n",
            "  train_runtime            = 0:19:27.88\n",
            "  train_samples_per_second =     23.119\n",
            "  train_steps_per_second   =      2.894\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following columns in the test set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: code, markdown, __index_level_0__. If code, markdown, __index_level_0__ are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Prediction *****\n",
            "  Num examples = 900\n",
            "  Batch size = 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "***** eval metrics *****\n",
            "  epoch                   =       10.0\n",
            "  eval_accuracy           =       0.68\n",
            "  eval_loss               =     0.6137\n",
            "  eval_runtime            = 0:00:14.60\n",
            "  eval_samples_per_second =     27.389\n",
            "  eval_steps_per_second   =      3.424\n",
            "***** predict metrics *****\n",
            "  predict_accuracy           =     0.7078\n",
            "  predict_loss               =     0.5996\n",
            "  predict_runtime            = 0:00:32.51\n",
            "  predict_samples_per_second =     27.678\n",
            "  predict_steps_per_second   =      3.475\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.72      0.71      0.72       470\n",
            "           1       0.69      0.70      0.70       430\n",
            "\n",
            "    accuracy                           0.71       900\n",
            "   macro avg       0.71      0.71      0.71       900\n",
            "weighted avg       0.71      0.71      0.71       900\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Test with GT"
      ],
      "metadata": {
        "id": "yQPaVWWIPPqJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predictions, labels, metrics = trainer.predict(tokenized_test_dataset['test'], metric_key_prefix=\"predict\")\n",
        "\n",
        "trainer.log_metrics(\"predict\", metrics)\n",
        "trainer.save_metrics(\"predict\", metrics)\n",
        "\n",
        "predictions = np.argmax(predictions, axis=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        },
        "id": "eB7d1-3P69BK",
        "outputId": "4380f7db-d473-47fd-a239-cbfb4498d624"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following columns in the test set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: __index_level_0__, code, markdown. If __index_level_0__, code, markdown are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Prediction *****\n",
            "  Num examples = 991\n",
            "  Batch size = 8\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "***** predict metrics *****\n",
            "  predict_accuracy           =     0.6186\n",
            "  predict_loss               =     0.6515\n",
            "  predict_runtime            = 0:00:36.35\n",
            "  predict_samples_per_second =     27.255\n",
            "  predict_steps_per_second   =       3.41\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(predictions, labels, labels=[0, 1]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mVXnO6Om7Gz-",
        "outputId": "a438b02f-daaf-4bc7-93d9-100922a496fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.59      0.63      0.61       464\n",
            "           1       0.65      0.61      0.63       527\n",
            "\n",
            "    accuracy                           0.62       991\n",
            "   macro avg       0.62      0.62      0.62       991\n",
            "weighted avg       0.62      0.62      0.62       991\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train with 8k samples"
      ],
      "metadata": {
        "id": "S-2upZc2NXpY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = df.sample(8000)\n",
        "dataset = create_dataset(data)\n",
        "tokenized_dataset = tokenize_dataset(dataset, tokenizer)\n",
        "trainer = create_trainer(tokenized_dataset, model, 10, 10)"
      ],
      "metadata": {
        "id": "nBOhDYWWNWDT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_result = trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ryJxV-c2UKRx",
        "outputId": "ab1a7515-227b-4fd1-d322-a2743a998086"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Currently training with a batch size of: 8\n",
            "The following columns in the training set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: __index_level_0__, code, markdown. If __index_level_0__, code, markdown are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running training *****\n",
            "  Num examples = 5,400\n",
            "  Num Epochs = 10\n",
            "  Instantaneous batch size per device = 8\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 6,750\n",
            "  Number of trainable parameters = 592,130\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='6301' max='6750' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [6301/6750 34:40 < 02:28, 3.03 it/s, Epoch 9.33/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.626000</td>\n",
              "      <td>0.596924</td>\n",
              "      <td>0.670000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.576300</td>\n",
              "      <td>0.587207</td>\n",
              "      <td>0.696250</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.610000</td>\n",
              "      <td>0.571790</td>\n",
              "      <td>0.681250</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.551500</td>\n",
              "      <td>0.586806</td>\n",
              "      <td>0.683750</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.532700</td>\n",
              "      <td>0.611897</td>\n",
              "      <td>0.655000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.649500</td>\n",
              "      <td>0.589258</td>\n",
              "      <td>0.681250</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.643400</td>\n",
              "      <td>0.556786</td>\n",
              "      <td>0.705000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.642700</td>\n",
              "      <td>0.555304</td>\n",
              "      <td>0.702500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.598000</td>\n",
              "      <td>0.556167</td>\n",
              "      <td>0.705000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Checkpoint destination directory test_trainer/checkpoint-500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
            "Saving model checkpoint to test_trainer/checkpoint-500\n",
            "Configuration saved in test_trainer/checkpoint-500/config.json\n",
            "Model weights saved in test_trainer/checkpoint-500/model.safetensors\n",
            "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: __index_level_0__, code, markdown. If __index_level_0__, code, markdown are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 800\n",
            "  Batch size = 8\n",
            "Checkpoint destination directory test_trainer/checkpoint-1000 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
            "Saving model checkpoint to test_trainer/checkpoint-1000\n",
            "Configuration saved in test_trainer/checkpoint-1000/config.json\n",
            "Model weights saved in test_trainer/checkpoint-1000/model.safetensors\n",
            "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: __index_level_0__, code, markdown. If __index_level_0__, code, markdown are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 800\n",
            "  Batch size = 8\n",
            "Checkpoint destination directory test_trainer/checkpoint-1500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
            "Saving model checkpoint to test_trainer/checkpoint-1500\n",
            "Configuration saved in test_trainer/checkpoint-1500/config.json\n",
            "Model weights saved in test_trainer/checkpoint-1500/model.safetensors\n",
            "Checkpoint destination directory test_trainer/checkpoint-2000 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
            "Saving model checkpoint to test_trainer/checkpoint-2000\n",
            "Configuration saved in test_trainer/checkpoint-2000/config.json\n",
            "Model weights saved in test_trainer/checkpoint-2000/model.safetensors\n",
            "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: __index_level_0__, code, markdown. If __index_level_0__, code, markdown are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 800\n",
            "  Batch size = 8\n",
            "Checkpoint destination directory test_trainer/checkpoint-2500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
            "Saving model checkpoint to test_trainer/checkpoint-2500\n",
            "Configuration saved in test_trainer/checkpoint-2500/config.json\n",
            "Model weights saved in test_trainer/checkpoint-2500/model.safetensors\n",
            "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: __index_level_0__, code, markdown. If __index_level_0__, code, markdown are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 800\n",
            "  Batch size = 8\n",
            "Checkpoint destination directory test_trainer/checkpoint-3000 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
            "Saving model checkpoint to test_trainer/checkpoint-3000\n",
            "Configuration saved in test_trainer/checkpoint-3000/config.json\n",
            "Model weights saved in test_trainer/checkpoint-3000/model.safetensors\n",
            "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: __index_level_0__, code, markdown. If __index_level_0__, code, markdown are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 800\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to test_trainer/tmp-checkpoint-3500\n",
            "Configuration saved in test_trainer/tmp-checkpoint-3500/config.json\n",
            "Model weights saved in test_trainer/tmp-checkpoint-3500/model.safetensors\n",
            "Saving model checkpoint to test_trainer/tmp-checkpoint-4000\n",
            "Configuration saved in test_trainer/tmp-checkpoint-4000/config.json\n",
            "Model weights saved in test_trainer/tmp-checkpoint-4000/model.safetensors\n",
            "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: __index_level_0__, code, markdown. If __index_level_0__, code, markdown are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 800\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to test_trainer/tmp-checkpoint-4500\n",
            "Configuration saved in test_trainer/tmp-checkpoint-4500/config.json\n",
            "Model weights saved in test_trainer/tmp-checkpoint-4500/model.safetensors\n",
            "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: __index_level_0__, code, markdown. If __index_level_0__, code, markdown are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 800\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to test_trainer/tmp-checkpoint-5000\n",
            "Configuration saved in test_trainer/tmp-checkpoint-5000/config.json\n",
            "Model weights saved in test_trainer/tmp-checkpoint-5000/model.safetensors\n",
            "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: __index_level_0__, code, markdown. If __index_level_0__, code, markdown are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 800\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to test_trainer/tmp-checkpoint-5500\n",
            "Configuration saved in test_trainer/tmp-checkpoint-5500/config.json\n",
            "Model weights saved in test_trainer/tmp-checkpoint-5500/model.safetensors\n",
            "Saving model checkpoint to test_trainer/tmp-checkpoint-6000\n",
            "Configuration saved in test_trainer/tmp-checkpoint-6000/config.json\n",
            "Model weights saved in test_trainer/tmp-checkpoint-6000/model.safetensors\n",
            "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: __index_level_0__, code, markdown. If __index_level_0__, code, markdown are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 800\n",
            "  Batch size = 8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "metrics = train_result.metrics\n",
        "trainer.save_model()  # Saves the tokenizer too for easy upload\n",
        "\n",
        "trainer.log_metrics(\"train\", metrics)\n",
        "trainer.save_metrics(\"train\", metrics)\n",
        "trainer.save_state()\n",
        "\n",
        "# Evaluation\n",
        "\n",
        "metrics = trainer.evaluate(eval_dataset=tokenized_dataset[\"eval\"].shuffle(seed=42))\n",
        "\n",
        "trainer.log_metrics(\"eval\", metrics)\n",
        "trainer.save_metrics(\"eval\", metrics)\n",
        "\n",
        "# Prediction\n",
        "\n",
        "predictions, labels, metrics = trainer.predict(tokenized_dataset[\"test\"], metric_key_prefix=\"predict\")\n",
        "\n",
        "trainer.log_metrics(\"predict\", metrics)\n",
        "trainer.save_metrics(\"predict\", metrics)\n",
        "\n",
        "predictions = np.argmax(predictions, axis=1)\n",
        "\n",
        "print(classification_report(predictions, labels, labels=[0, 1]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 762
        },
        "id": "wzB7_v3hULNA",
        "outputId": "456ed5dd-10fe-43e0-eb99-0866a6305eff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Saving model checkpoint to test_trainer\n",
            "Configuration saved in test_trainer/config.json\n",
            "Model weights saved in test_trainer/model.safetensors\n",
            "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: code, markdown, __index_level_0__. If code, markdown, __index_level_0__ are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 800\n",
            "  Batch size = 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "***** train metrics *****\n",
            "  epoch                    =       10.0\n",
            "  total_flos               = 13232228GF\n",
            "  train_loss               =     0.6248\n",
            "  train_runtime            = 0:38:51.35\n",
            "  train_samples_per_second =     23.163\n",
            "  train_steps_per_second   =      2.895\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following columns in the test set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: code, markdown, __index_level_0__. If code, markdown, __index_level_0__ are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Prediction *****\n",
            "  Num examples = 1800\n",
            "  Batch size = 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "***** eval metrics *****\n",
            "  epoch                   =       10.0\n",
            "  eval_accuracy           =       0.68\n",
            "  eval_loss               =      0.577\n",
            "  eval_runtime            = 0:00:29.03\n",
            "  eval_samples_per_second =     27.553\n",
            "  eval_steps_per_second   =      3.444\n",
            "***** predict metrics *****\n",
            "  predict_accuracy           =     0.7144\n",
            "  predict_loss               =     0.5674\n",
            "  predict_runtime            = 0:01:04.11\n",
            "  predict_samples_per_second =     28.077\n",
            "  predict_steps_per_second   =       3.51\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.69      0.72      0.71       861\n",
            "           1       0.74      0.71      0.72       939\n",
            "\n",
            "    accuracy                           0.71      1800\n",
            "   macro avg       0.71      0.71      0.71      1800\n",
            "weighted avg       0.72      0.71      0.71      1800\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Test with GT"
      ],
      "metadata": {
        "id": "-z28hgLkPUyU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predictions, labels, metrics = trainer.predict(tokenized_test_dataset['test'], metric_key_prefix=\"predict\")\n",
        "\n",
        "trainer.log_metrics(\"predict\", metrics)\n",
        "trainer.save_metrics(\"predict\", metrics)\n",
        "\n",
        "predictions = np.argmax(predictions, axis=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 453
        },
        "id": "C0u5LJOY7JWE",
        "outputId": "2ff997f2-eedf-4685-a46c-de731afa11a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following columns in the test set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: __index_level_0__, code, markdown. If __index_level_0__, code, markdown are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Prediction *****\n",
            "  Num examples = 991\n",
            "  Batch size = 8\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='3444' max='6750' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [3444/6750 18:52 < 18:08, 3.04 it/s, Epoch 5.10/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.662100</td>\n",
              "      <td>0.647064</td>\n",
              "      <td>0.667500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.643900</td>\n",
              "      <td>0.627734</td>\n",
              "      <td>0.651250</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.626600</td>\n",
              "      <td>0.600095</td>\n",
              "      <td>0.687500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.651900</td>\n",
              "      <td>0.610050</td>\n",
              "      <td>0.660000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.600300</td>\n",
              "      <td>0.625951</td>\n",
              "      <td>0.628750</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>\n",
              "    <div>\n",
              "      \n",
              "      <progress value='124' max='124' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [124/124 00:33]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "***** predict metrics *****\n",
            "  predict_accuracy           =     0.6115\n",
            "  predict_loss               =      0.655\n",
            "  predict_runtime            = 0:00:34.71\n",
            "  predict_samples_per_second =     28.548\n",
            "  predict_steps_per_second   =      3.572\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(predictions, labels, labels=[0, 1]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YQG9Ul3S7OTn",
        "outputId": "15fa64bd-ff6d-43e1-85bb-a3ed7fcb4b87"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.59      0.62      0.61       477\n",
            "           1       0.63      0.60      0.62       514\n",
            "\n",
            "    accuracy                           0.61       991\n",
            "   macro avg       0.61      0.61      0.61       991\n",
            "weighted avg       0.61      0.61      0.61       991\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train with 10k samples"
      ],
      "metadata": {
        "id": "lPftROEVrWLY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = df.copy()\n",
        "dataset = create_dataset(data)\n",
        "tokenized_dataset = tokenize_dataset(dataset, tokenizer)\n",
        "trainer = create_trainer(tokenized_dataset, model, 10, 10)"
      ],
      "metadata": {
        "id": "5cAHqmdvrmWI"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_result = trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "pWclNpxxuvkJ",
        "outputId": "ec566591-5259-4f2e-d626-20f9a560f65d"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Currently training with a batch size of: 8\n",
            "The following columns in the training set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: code, markdown, __index_level_0__. If code, markdown, __index_level_0__ are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running training *****\n",
            "  Num examples = 6,424\n",
            "  Num Epochs = 40\n",
            "  Instantaneous batch size per device = 8\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 32,120\n",
            "  Number of trainable parameters = 592,130\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='10456' max='32120' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [10456/32120 58:04 < 2:00:21, 3.00 it/s, Epoch 13.02/40]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.665500</td>\n",
              "      <td>0.631581</td>\n",
              "      <td>0.696429</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.617800</td>\n",
              "      <td>0.631441</td>\n",
              "      <td>0.632353</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.630900</td>\n",
              "      <td>0.583330</td>\n",
              "      <td>0.700630</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.582700</td>\n",
              "      <td>0.574614</td>\n",
              "      <td>0.702731</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.602200</td>\n",
              "      <td>0.568319</td>\n",
              "      <td>0.700630</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.613800</td>\n",
              "      <td>0.583655</td>\n",
              "      <td>0.703782</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.607700</td>\n",
              "      <td>0.569142</td>\n",
              "      <td>0.720588</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.631700</td>\n",
              "      <td>0.565123</td>\n",
              "      <td>0.718487</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.566700</td>\n",
              "      <td>0.573619</td>\n",
              "      <td>0.714286</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.597900</td>\n",
              "      <td>0.554583</td>\n",
              "      <td>0.715336</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11</td>\n",
              "      <td>0.591800</td>\n",
              "      <td>0.555805</td>\n",
              "      <td>0.723739</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>0.625800</td>\n",
              "      <td>0.594629</td>\n",
              "      <td>0.696429</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13</td>\n",
              "      <td>0.616500</td>\n",
              "      <td>0.548875</td>\n",
              "      <td>0.715336</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Checkpoint destination directory test_trainer/checkpoint-500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
            "Saving model checkpoint to test_trainer/checkpoint-500\n",
            "Configuration saved in test_trainer/checkpoint-500/config.json\n",
            "Model weights saved in test_trainer/checkpoint-500/model.safetensors\n",
            "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: code, markdown, __index_level_0__. If code, markdown, __index_level_0__ are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 952\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to test_trainer/tmp-checkpoint-1000\n",
            "Configuration saved in test_trainer/tmp-checkpoint-1000/config.json\n",
            "Model weights saved in test_trainer/tmp-checkpoint-1000/model.safetensors\n",
            "Saving model checkpoint to test_trainer/tmp-checkpoint-1500\n",
            "Configuration saved in test_trainer/tmp-checkpoint-1500/config.json\n",
            "Model weights saved in test_trainer/tmp-checkpoint-1500/model.safetensors\n",
            "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: code, markdown, __index_level_0__. If code, markdown, __index_level_0__ are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 952\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to test_trainer/tmp-checkpoint-2000\n",
            "Configuration saved in test_trainer/tmp-checkpoint-2000/config.json\n",
            "Model weights saved in test_trainer/tmp-checkpoint-2000/model.safetensors\n",
            "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: code, markdown, __index_level_0__. If code, markdown, __index_level_0__ are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 952\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to test_trainer/tmp-checkpoint-2500\n",
            "Configuration saved in test_trainer/tmp-checkpoint-2500/config.json\n",
            "Model weights saved in test_trainer/tmp-checkpoint-2500/model.safetensors\n",
            "Saving model checkpoint to test_trainer/tmp-checkpoint-3000\n",
            "Configuration saved in test_trainer/tmp-checkpoint-3000/config.json\n",
            "Model weights saved in test_trainer/tmp-checkpoint-3000/model.safetensors\n",
            "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: code, markdown, __index_level_0__. If code, markdown, __index_level_0__ are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 952\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to test_trainer/tmp-checkpoint-3500\n",
            "Configuration saved in test_trainer/tmp-checkpoint-3500/config.json\n",
            "Model weights saved in test_trainer/tmp-checkpoint-3500/model.safetensors\n",
            "Saving model checkpoint to test_trainer/tmp-checkpoint-4000\n",
            "Configuration saved in test_trainer/tmp-checkpoint-4000/config.json\n",
            "Model weights saved in test_trainer/tmp-checkpoint-4000/model.safetensors\n",
            "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: code, markdown, __index_level_0__. If code, markdown, __index_level_0__ are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 952\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to test_trainer/tmp-checkpoint-4500\n",
            "Configuration saved in test_trainer/tmp-checkpoint-4500/config.json\n",
            "Model weights saved in test_trainer/tmp-checkpoint-4500/model.safetensors\n",
            "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: code, markdown, __index_level_0__. If code, markdown, __index_level_0__ are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 952\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to test_trainer/tmp-checkpoint-5000\n",
            "Configuration saved in test_trainer/tmp-checkpoint-5000/config.json\n",
            "Model weights saved in test_trainer/tmp-checkpoint-5000/model.safetensors\n",
            "Saving model checkpoint to test_trainer/tmp-checkpoint-5500\n",
            "Configuration saved in test_trainer/tmp-checkpoint-5500/config.json\n",
            "Model weights saved in test_trainer/tmp-checkpoint-5500/model.safetensors\n",
            "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: code, markdown, __index_level_0__. If code, markdown, __index_level_0__ are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 952\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to test_trainer/tmp-checkpoint-6000\n",
            "Configuration saved in test_trainer/tmp-checkpoint-6000/config.json\n",
            "Model weights saved in test_trainer/tmp-checkpoint-6000/model.safetensors\n",
            "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: code, markdown, __index_level_0__. If code, markdown, __index_level_0__ are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 952\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to test_trainer/tmp-checkpoint-6500\n",
            "Configuration saved in test_trainer/tmp-checkpoint-6500/config.json\n",
            "Model weights saved in test_trainer/tmp-checkpoint-6500/model.safetensors\n",
            "Saving model checkpoint to test_trainer/tmp-checkpoint-7000\n",
            "Configuration saved in test_trainer/tmp-checkpoint-7000/config.json\n",
            "Model weights saved in test_trainer/tmp-checkpoint-7000/model.safetensors\n",
            "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: code, markdown, __index_level_0__. If code, markdown, __index_level_0__ are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 952\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to test_trainer/tmp-checkpoint-7500\n",
            "Configuration saved in test_trainer/tmp-checkpoint-7500/config.json\n",
            "Model weights saved in test_trainer/tmp-checkpoint-7500/model.safetensors\n",
            "Saving model checkpoint to test_trainer/tmp-checkpoint-8000\n",
            "Configuration saved in test_trainer/tmp-checkpoint-8000/config.json\n",
            "Model weights saved in test_trainer/tmp-checkpoint-8000/model.safetensors\n",
            "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: code, markdown, __index_level_0__. If code, markdown, __index_level_0__ are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 952\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to test_trainer/tmp-checkpoint-8500\n",
            "Configuration saved in test_trainer/tmp-checkpoint-8500/config.json\n",
            "Model weights saved in test_trainer/tmp-checkpoint-8500/model.safetensors\n",
            "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: code, markdown, __index_level_0__. If code, markdown, __index_level_0__ are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 952\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to test_trainer/tmp-checkpoint-9000\n",
            "Configuration saved in test_trainer/tmp-checkpoint-9000/config.json\n",
            "Model weights saved in test_trainer/tmp-checkpoint-9000/model.safetensors\n",
            "Saving model checkpoint to test_trainer/tmp-checkpoint-9500\n",
            "Configuration saved in test_trainer/tmp-checkpoint-9500/config.json\n",
            "Model weights saved in test_trainer/tmp-checkpoint-9500/model.safetensors\n",
            "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: code, markdown, __index_level_0__. If code, markdown, __index_level_0__ are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 952\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to test_trainer/tmp-checkpoint-10000\n",
            "Configuration saved in test_trainer/tmp-checkpoint-10000/config.json\n",
            "Model weights saved in test_trainer/tmp-checkpoint-10000/model.safetensors\n",
            "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: code, markdown, __index_level_0__. If code, markdown, __index_level_0__ are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 952\n",
            "  Batch size = 8\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-69-a6eca412ee9e>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1622\u001b[0m                 \u001b[0mhf_hub_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_progress_bars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1623\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1624\u001b[0;31m             return inner_training_loop(\n\u001b[0m\u001b[1;32m   1625\u001b[0m                 \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1626\u001b[0m                 \u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   1964\u001b[0m                     \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogging_nan_inf_filter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1965\u001b[0m                     \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_torch_tpu_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1966\u001b[0;31m                     \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtr_loss_step\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misinf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtr_loss_step\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1967\u001b[0m                 ):\n\u001b[1;32m   1968\u001b[0m                     \u001b[0;31m# if loss is nan or inf simply add the average of previous logged losses\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "metrics = train_result.metrics\n",
        "trainer.save_model()  # Saves the tokenizer too for easy upload\n",
        "\n",
        "trainer.log_metrics(\"train\", metrics)\n",
        "trainer.save_metrics(\"train\", metrics)\n",
        "trainer.save_state()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xEWMQNXkuyza",
        "outputId": "555ba462-3787-4385-e778-97d2a42eb082"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Saving model checkpoint to test_trainer\n",
            "Configuration saved in test_trainer/config.json\n",
            "Model weights saved in test_trainer/model.safetensors\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "***** train metrics *****\n",
            "  epoch                    =       10.0\n",
            "  total_flos               =  1654028GF\n",
            "  train_loss               =     0.6817\n",
            "  train_runtime            = 0:04:38.69\n",
            "  train_samples_per_second =      24.22\n",
            "  train_steps_per_second   =       3.05\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluation\n",
        "\n",
        "metrics = trainer.evaluate(eval_dataset=tokenized_dataset[\"eval\"].shuffle(seed=42))\n",
        "\n",
        "trainer.log_metrics(\"eval\", metrics)\n",
        "trainer.save_metrics(\"eval\", metrics)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 630
        },
        "id": "yt5V9hUDu6_E",
        "outputId": "b183f63d-84d2-44dc-96f5-f389f5a918f7"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: code, markdown, __index_level_0__. If code, markdown, __index_level_0__ are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 952\n",
            "  Batch size = 8\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='10456' max='32120' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [10456/32120 58:04 < 2:00:21, 3.00 it/s, Epoch 13.02/40]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.665500</td>\n",
              "      <td>0.631581</td>\n",
              "      <td>0.696429</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.617800</td>\n",
              "      <td>0.631441</td>\n",
              "      <td>0.632353</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.630900</td>\n",
              "      <td>0.583330</td>\n",
              "      <td>0.700630</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.582700</td>\n",
              "      <td>0.574614</td>\n",
              "      <td>0.702731</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.602200</td>\n",
              "      <td>0.568319</td>\n",
              "      <td>0.700630</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.613800</td>\n",
              "      <td>0.583655</td>\n",
              "      <td>0.703782</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.607700</td>\n",
              "      <td>0.569142</td>\n",
              "      <td>0.720588</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.631700</td>\n",
              "      <td>0.565123</td>\n",
              "      <td>0.718487</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.566700</td>\n",
              "      <td>0.573619</td>\n",
              "      <td>0.714286</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.597900</td>\n",
              "      <td>0.554583</td>\n",
              "      <td>0.715336</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11</td>\n",
              "      <td>0.591800</td>\n",
              "      <td>0.555805</td>\n",
              "      <td>0.723739</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>0.625800</td>\n",
              "      <td>0.594629</td>\n",
              "      <td>0.696429</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13</td>\n",
              "      <td>0.584600</td>\n",
              "      <td>0.550155</td>\n",
              "      <td>0.715336</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "***** eval metrics *****\n",
            "  eval_accuracy = 0.7153\n",
            "  eval_loss     = 0.5502\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Prediction\n",
        "\n",
        "predictions, labels, metrics = trainer.predict(tokenized_dataset[\"test\"], metric_key_prefix=\"predict\")\n",
        "\n",
        "trainer.log_metrics(\"predict\", metrics)\n",
        "trainer.save_metrics(\"predict\", metrics)\n",
        "\n",
        "predictions = np.argmax(predictions, axis=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 704
        },
        "id": "dviopTHRu9le",
        "outputId": "d5848749-c5ce-4393-8c8b-0ff0300c8891"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following columns in the test set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: code, markdown, __index_level_0__. If code, markdown, __index_level_0__ are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Prediction *****\n",
            "  Num examples = 2142\n",
            "  Batch size = 8\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='10456' max='32120' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [10456/32120 58:04 < 2:00:21, 3.00 it/s, Epoch 13.02/40]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.665500</td>\n",
              "      <td>0.631581</td>\n",
              "      <td>0.696429</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.617800</td>\n",
              "      <td>0.631441</td>\n",
              "      <td>0.632353</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.630900</td>\n",
              "      <td>0.583330</td>\n",
              "      <td>0.700630</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.582700</td>\n",
              "      <td>0.574614</td>\n",
              "      <td>0.702731</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.602200</td>\n",
              "      <td>0.568319</td>\n",
              "      <td>0.700630</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.613800</td>\n",
              "      <td>0.583655</td>\n",
              "      <td>0.703782</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.607700</td>\n",
              "      <td>0.569142</td>\n",
              "      <td>0.720588</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.631700</td>\n",
              "      <td>0.565123</td>\n",
              "      <td>0.718487</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.566700</td>\n",
              "      <td>0.573619</td>\n",
              "      <td>0.714286</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.597900</td>\n",
              "      <td>0.554583</td>\n",
              "      <td>0.715336</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11</td>\n",
              "      <td>0.591800</td>\n",
              "      <td>0.555805</td>\n",
              "      <td>0.723739</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>0.625800</td>\n",
              "      <td>0.594629</td>\n",
              "      <td>0.696429</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13</td>\n",
              "      <td>0.584600</td>\n",
              "      <td>0.550155</td>\n",
              "      <td>0.715336</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>\n",
              "    <div>\n",
              "      \n",
              "      <progress value='268' max='268' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [268/268 01:11]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "***** predict metrics *****\n",
            "  predict_accuracy           =     0.7092\n",
            "  predict_loss               =     0.5461\n",
            "  predict_runtime            = 0:01:11.71\n",
            "  predict_samples_per_second =     29.868\n",
            "  predict_steps_per_second   =      3.737\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(predictions, labels, labels=[0, 1]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jy7c7rKju_7I",
        "outputId": "818bd839-f192-41b6-8da0-4fb8f868bc92"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.67      0.73      1285\n",
            "           1       0.61      0.77      0.68       857\n",
            "\n",
            "    accuracy                           0.71      2142\n",
            "   macro avg       0.71      0.72      0.71      2142\n",
            "weighted avg       0.73      0.71      0.71      2142\n",
            "\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "tHqBgUUyaLq-",
        "vUIuU9p2WuID",
        "v1MHd39ZPpxA",
        "ZidvgBTxsnwZ",
        "IJ6KqqfPvILP",
        "Q95XYQfjNLKh",
        "S-2upZc2NXpY",
        "lPftROEVrWLY"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {}
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}